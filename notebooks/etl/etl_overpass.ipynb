{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0ac0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ¡Dimensión actualizada y normalizada correctamente!\n",
      " Guardada en: H:/git/proyecto grupal 2/Yelp-Gmaps-Proyecto-DS/data/processed/dim/dim_nombre_restaurante_actualizada.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# librerías\n",
    "import json\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import unicodedata\n",
    "\n",
    "\"\"\"\n",
    "Realizamos un ETL a los archivos extraídos de Overpass Turbo,\n",
    "normalizando todos los nombres y generando IDs únicos.\n",
    "\"\"\"\n",
    "\n",
    "#Función para normalizar textos\n",
    "def normalizar_texto(texto):\n",
    "    texto = str(texto).lower().strip()\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')\n",
    "    return texto\n",
    "\n",
    "# Generamos IDs únicos para los nombres de los lugares \n",
    "def generar_id(nombre):\n",
    "    normalizado = normalizar_texto(nombre)\n",
    "    return \"NOM\" + hashlib.md5(normalizado.encode()).hexdigest()[:6].upper()\n",
    "\n",
    "# Cargamos el archivo JSON de Overpass Turbo\n",
    "ruta_json_overpass = r'H:/git/proyecto grupal 2/Yelp-Gmaps-Proyecto-DS/data/raw/overpass-turbo.eu/export.json'\n",
    "with open(ruta_json_overpass, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 📦 Extraer nombres únicos\n",
    "nombres_nuevos = []\n",
    "for elemento in data.get('elements', []):\n",
    "    tags = elemento.get('tags', {})\n",
    "    nombre = tags.get('name')\n",
    "    if nombre:\n",
    "        nombres_nuevos.append(normalizar_texto(nombre))\n",
    "\n",
    "#  Eliminamos los duplicados locales\n",
    "nombres_nuevos = sorted(set(nombres_nuevos))\n",
    "\n",
    "# 📂 Cargamos la dimensión existente y normalizar sus nombres\n",
    "ruta_dim_existente = r'H:\\git\\proyecto grupal 2\\Yelp-Gmaps-Proyecto-DS\\data\\processed\\dim\\dim_nombre_restaurante.csv'\n",
    "df_dim = pd.read_csv(ruta_dim_existente)\n",
    "df_dim['nombre'] = df_dim['nombre'].astype(str).apply(normalizar_texto)\n",
    "\n",
    "# Determinamos los nombres que aún no están en la dimensión\n",
    "nombres_existentes = set(df_dim['nombre'])\n",
    "nombres_a_agregar = [n for n in nombres_nuevos if n not in nombres_existentes]\n",
    "\n",
    "# Creamos un DataFrame con los nuevos registros\n",
    "nuevos_registros = pd.DataFrame({\n",
    "    'id_nombre': [generar_id(nombre) for nombre in nombres_a_agregar],\n",
    "    'nombre': nombres_a_agregar\n",
    "})\n",
    "\n",
    "# Concatenamos lo nuevos registros con la dimensión existente\n",
    "df_dim_actualizada = pd.concat([df_dim, nuevos_registros], ignore_index=True)\n",
    "df_dim_actualizada = df_dim_actualizada.drop_duplicates(subset='nombre')\n",
    "\n",
    "# Guardamos la dimensión actualizada\n",
    "ruta_salida_dim = r'H:/git/proyecto grupal 2/Yelp-Gmaps-Proyecto-DS/data/processed/dim/dim_nombre_restaurante_actualizada.csv'\n",
    "df_dim_actualizada.to_csv(ruta_salida_dim, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\" ¡Dimensión actualizada y normalizada correctamente!\\n Guardada en: {ruta_salida_dim}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
